<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Aligning single-cell resolution spatial transcriptomics data to H&amp;E staining image from Visium &mdash; STalign 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=f2a433a1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            STalign
              <img src="https://raw.githubusercontent.com/JEFworks-Lab/STalign/main/STalign_logos_fin.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html#installation-import">Installation &amp; Import</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html#input-data">Input Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview.html#usage">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../STalign.html">Functions</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">STalign</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Aligning single-cell resolution spatial transcriptomics data to H&amp;E staining image from Visium</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/merfish-visium-alignment-with-curve-annotator.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Aligning-single-cell-resolution-spatial-transcriptomics-data-to-H&amp;E-staining-image-from-Visium">
<h1>Aligning single-cell resolution spatial transcriptomics data to H&amp;E staining image from Visium<a class="headerlink" href="#Aligning-single-cell-resolution-spatial-transcriptomics-data-to-H&E-staining-image-from-Visium" title="Link to this heading">ÔÉÅ</a></h1>
<p>In this notebook, we take a single cell resolution spatial transcriptomics datasets of a coronal section of the adult mouse brain profiled by the MERFISH technology and align it to a H&amp;E staining image from a different individual at matched locations with respect to bregma.</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">STalign</span></code> to achieve this alignment. We will first load the relevant code libraries.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## import dependencies
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.transforms as mtransforms
import pandas as pd
import torch
import plotly
import requests

# make plots bigger
plt.rcParams[&quot;figure.figsize&quot;] = (12,10)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## skip cell if STalign.py in same folder as notebook
import sys
sys.path.append(&quot;../../STalign&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>## import STalign from upper directory
import STalign
</pre></div>
</div>
</div>
<p>We can read in the single cell information using <code class="docutils literal notranslate"><span class="pre">pandas</span></code> as <code class="docutils literal notranslate"><span class="pre">pd</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Single cell data 1
# read in data
fname = &#39;../merfish_data/datasets_mouse_brain_map_BrainReceptorShowcase_Slice2_Replicate3_cell_metadata_S2R3.csv.gz&#39;
df1 = pd.read_csv(fname)
print(df1.head())
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                Unnamed: 0  fov       volume    center_x
0  158338042824236264719696604356349910479   33   532.778772  617.916619  \
1  260594727341160372355976405428092853003   33  1004.430016  596.808018
2  307643940700812339199503248604719950662   33  1267.183208  578.880018
3   30863303465976316429997331474071348973   33  1403.401822  572.616017
4  313162718584097621688679244357302162401   33   507.949497  608.364018

      center_y       min_x       max_x        min_y        max_y
0  2666.520010  614.725219  621.108019  2657.545209  2675.494810
1  2763.450012  589.669218  603.946818  2757.013212  2769.886812
2  2748.978012  570.877217  586.882818  2740.489211  2757.466812
3  2766.690012  564.937217  580.294818  2756.581212  2776.798812
4  2687.418010  603.061218  613.666818  2682.493210  2692.342810
</pre></div></div>
</div>
<p>For alignment with <code class="docutils literal notranslate"><span class="pre">STalign</span></code>, we only need the cell centroid information. So we can pull out this information. We can further visualize the cell centroids to get a sense of the variation in cell density that we will be relying on for our alignment by plotting using <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> as <code class="docutils literal notranslate"><span class="pre">plt</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># get cell centroid coordinates
xI = np.array(df1[&#39;center_x&#39;])
yI = np.array(df1[&#39;center_y&#39;])

# plot
fig,ax = plt.subplots()
ax.scatter(xI,yI,s=1,alpha=0.2)
#ax.set_aspect(&#39;equal&#39;, &#39;box&#39;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.collections.PathCollection at 0x168cccbe0&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_8_1.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_8_1.png" />
</div>
</div>
<p>We will use STalign to rasterize the single cell centroid positions into an image. Assuming the single-cell centroid coordinates are in microns, we will perform this rasterization at a 30 micron resolution. We can visualize the resulting rasterized image.</p>
<p>Note that points are plotting with the origin at bottom left while images are typically plotted with origin at top left so we‚Äôve used <code class="docutils literal notranslate"><span class="pre">invert_yaxis()</span></code> to invert the yaxis for visualization consistency.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># rasterize at 30um resolution (assuming positions are in um units) and plot
XI,YI,I,fig = STalign.rasterize(xI, yI, dx=30)

ax = fig.axes[0]
ax.invert_yaxis()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0 of 85958
10000 of 85958
20000 of 85958
30000 of 85958
40000 of 85958
50000 of 85958
60000 of 85958
70000 of 85958
80000 of 85958
85957 of 85958
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_10_1.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_10_1.png" />
</div>
</div>
<p>Note that this is a 1D greyscale image. To align with an RGB H&amp;E image, we will need to make our greyscale image into RGB by simply stacking the 1D values 3 times. We will also normalize to get intensity values between 0 to 1.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(&quot;The initial shape of I is {}&quot;.format(I.shape))
I = np.vstack((I, I, I)) # make into 3xNxM
print(&quot;The range of I is {} to {}&quot;.format(I.min(), I.max() ))

# normalize
I = STalign.normalize(I)
print(&quot;The range of I after normalization is {} to {}&quot;.format(I.min(), I.max() ))

# double check size of things
print(&quot;The new shape of I is {}&quot;.format(I.shape))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The initial shape of I is (1, 256, 336)
The range of I is 0.0 to 4.715485184477206
The range of I after normalization is 0.0 to 1.0
The new shape of I is (3, 256, 336)
</pre></div></div>
</div>
<p>We have already downloaded the H&amp;E staining image from <a class="reference external" href="https://www.10xgenomics.com/resources/datasets/adult-mouse-brain-ffpe-1-standard-1-3-0">https://www.10xgenomics.com/resources/datasets/adult-mouse-brain-ffpe-1-standard-1-3-0</a> and placed the file in a folder called <code class="docutils literal notranslate"><span class="pre">visium_data</span></code></p>
<p>We can read in the H&amp;E staining image using <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> as <code class="docutils literal notranslate"><span class="pre">plt</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>image_file = &#39;../visium_data/tissue_hires_image.png&#39;
V = plt.imread(image_file)

# plot
fig,ax = plt.subplots()
ax.imshow(V)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.image.AxesImage at 0x15f5635e0&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_14_1.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_14_1.png" />
</div>
</div>
<p>Note that this is an RGB image that <code class="docutils literal notranslate"><span class="pre">matplotlib.pyplot</span></code> had read in as an NxMx3 matrix with values ranging from 0 to 1. We will use <code class="docutils literal notranslate"><span class="pre">STalign</span></code> to normalize the image in case there are any outlier intensities.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(&quot;The initial shape of V is {}&quot;.format(V.shape))
print(&quot;The range of V is {} to {}&quot;.format(V.min(), V.max() ))

Vnorm = STalign.normalize(V)
print(&quot;The range of V after normalization is {} to {}&quot;.format(Vnorm.min(), Vnorm.max() ))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The initial shape of V is (2000, 1838, 3)
The range of V is 0.10588235408067703 to 1.0
The range of V after normalization is 0.0 to 1.0
</pre></div></div>
</div>
<p>We will transpose <code class="docutils literal notranslate"><span class="pre">Vnorm</span></code> to be a 3xNxM matrix <code class="docutils literal notranslate"><span class="pre">J</span></code> for downstream analyses. We will also create some variances <code class="docutils literal notranslate"><span class="pre">YJ</span></code> and <code class="docutils literal notranslate"><span class="pre">XJ</span></code> to keep track of the image size.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>J = Vnorm.transpose(2,0,1)
print(&quot;The new shape of J is {}&quot;.format(J.shape))

YJ = np.array(range(J.shape[1]))*1. # needs to be longs not doubles for STalign.transform later so multiply by 1.
XJ = np.array(range(J.shape[2]))*1. # needs to be longs not doubles for STalign.transform later so multiply by 1.
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The new shape of J is (3, 2000, 1838)
</pre></div></div>
</div>
<p>We now have a rasterized image corresponding to the single cell positions from the spatial transcriptomics data and an H&amp;E image that we can align. Note, that we have specified the image from cell positions as source <code class="docutils literal notranslate"><span class="pre">I</span></code> and the H&amp;E image as target <code class="docutils literal notranslate"><span class="pre">J</span></code> because the H&amp;E image is only one hemisphere of the brain. We advise choosing the more complete tissue section as the source such that every observation in the target has some correspondence in the source.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># plot
extentI = STalign.extent_from_x((YI,XI))

fig,ax = plt.subplots(1,2)
ax[0].imshow((I.transpose(1,2,0).squeeze()), extent=extentI)
ax[0].invert_yaxis()
ax[0].set_title(&#39;source&#39;, fontsize=15)
ax[1].imshow((J).transpose(1,2,0))
ax[1].set_title(&#39;target&#39;, fontsize=15)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;target&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_20_1.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_20_1.png" />
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">STalign</span></code> relies on an interative gradient descent to align these two images. This can be somewhat slow. So we can manually designate a few landmark points to help initialize the alignment. A <code class="docutils literal notranslate"><span class="pre">curve_annotator.py</span></code> script is provided to assist with this. In order to use the <code class="docutils literal notranslate"><span class="pre">curve_annotator.py</span></code> script, we will need to write out our images as <code class="docutils literal notranslate"><span class="pre">.npz</span></code> files.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>np.savez(&#39;../visium_data/Merfish_S2_R3&#39;, x=XI,y=YI,I=I)
np.savez(&#39;../visium_data/tissue_hires_image&#39;, x=XJ,y=YJ,I=J)
</pre></div>
</div>
</div>
<p>Given these <code class="docutils literal notranslate"><span class="pre">.npz</span></code> files, we can then run the following code on the command line from inside the <code class="docutils literal notranslate"><span class="pre">notebooks</span></code> folder:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>python ../../STalign/curve_annotator.py ../visium_data/Merfish_S2_R3.npz
python ../../STalign/curve_annotator.py ../visium_data/tissue_hires_image.npz
</pre></div>
</div>
<p>Which will provide a graphical user interface to selecting curves. Using the flag <code class="docutils literal notranslate"><span class="pre">-o</span></code> , these curves will saved as <code class="docutils literal notranslate"><span class="pre">Merfish_S2_R3_curves.npy</span></code> and <code class="docutils literal notranslate"><span class="pre">tissue_hires_image_curves.npy</span></code> respectively. We can then read in these files.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># read from file
pointsIlist = np.load(&#39;../visium_data/Merfish_S2_R3_curves.npy&#39;, allow_pickle=True).tolist()
print(pointsIlist)
pointsJlist = np.load(&#39;../visium_data/tissue_hires_image_curves.npy&#39;, allow_pickle=True).tolist()
print(pointsJlist)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;first&#39;: [(4951.508612888981, 6678.213688121723), (5190.4696518500195, 839.2526491606832)], &#39;second&#39;: [(5117.742379122747, 911.9799218879562), (8442.417703798072, 891.2007011087353)], &#39;third&#39;: [(8317.742379122747, 860.031869939904), (9533.326794707162, 3769.122779030813), (8868.391729772098, 5909.382519290553), (7403.456664837032, 6886.0058959139305), (5367.093028473396, 7104.1877140957495), (4941.11900249937, 6709.382519290554)]}
{&#39;first&#39;: [(458.5432900432901, 715.9502164502164), (788.6298701298703, 1773.8506493506493)], &#39;second&#39;: [(785.9242424242426, 1773.8506493506493), (1367.6341991341992, 1771.1450216450216)], &#39;third&#39;: [(1381.162337662338, 1752.2056277056276), (1478.5649350649355, 1546.577922077922), (1494.7987012987014, 1308.482683982684), (1451.5086580086581, 1035.2142857142858), (1362.222943722944, 883.699134199134), (1208.0021645021648, 745.7121212121212), (1040.253246753247, 642.8982683982683), (867.0930735930739, 605.0194805194806), (688.5216450216452, 615.8419913419914), (564.0627705627707, 648.3095238095239), (455.83766233766244, 715.9502164502164)]}
</pre></div></div>
</div>
<p>Note that these landmark points are read in as lists. We will want to convert them to a simple array for downstream usage.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># convert to array
pointsI = []
pointsJ = []

# Jean&#39;s note: a bit odd to me that the points are stored as y,x
## instead of x,y but all downstream code uses this orientation
for i in pointsIlist.keys():
    for j in range(len(pointsIlist[i])):
        pointsI.append([pointsIlist[i][j][1], pointsIlist[i][j][0]])
for i in pointsJlist.keys():
    for j in range(len(pointsJlist[i])):
        pointsJ.append([pointsJlist[i][j][1], pointsJlist[i][j][0]])

pointsI = np.array(pointsI)
pointsJ = np.array(pointsJ)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># now arrays
print(pointsI)
print(pointsJ)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[6678.21368812 4951.50861289]
 [ 839.25264916 5190.46965185]
 [ 911.97992189 5117.74237912]
 [ 891.20070111 8442.4177038 ]
 [ 860.03186994 8317.74237912]
 [3769.12277903 9533.32679471]
 [5909.38251929 8868.39172977]
 [6886.00589591 7403.45666484]
 [7104.1877141  5367.09302847]
 [6709.38251929 4941.1190025 ]]
[[ 715.95021645  458.54329004]
 [1773.85064935  788.62987013]
 [1773.85064935  785.92424242]
 [1771.14502165 1367.63419913]
 [1752.20562771 1381.16233766]
 [1546.57792208 1478.56493506]
 [1308.48268398 1494.7987013 ]
 [1035.21428571 1451.50865801]
 [ 883.6991342  1362.22294372]
 [ 745.71212121 1208.0021645 ]
 [ 642.8982684  1040.25324675]
 [ 605.01948052  867.09307359]
 [ 615.84199134  688.52164502]
 [ 648.30952381  564.06277056]
 [ 715.95021645  455.83766234]]
</pre></div></div>
</div>
<p>We can double check that our landmark points look sensible by plotting them along with the rasterized image we created.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># manually make corresponding points
#data = np.load(&#39;../visium_data/visium2_points.npz&#39;)
#pointsI = np.array(data[&#39;pointsI&#39;][...,::-1])
#pointsJ = np.array(data[&#39;pointsJ&#39;][...,::-1])
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># plot
extentJ = STalign.extent_from_x((YJ,XJ))
extentI = STalign.extent_from_x((YI,XI))

fig,ax = plt.subplots(1,2)
ax[0].imshow((I.transpose(1,2,0).squeeze()), extent=extentI)
ax[1].imshow((J.transpose(1,2,0).squeeze()), extent=extentJ)

trans_offset_0 = mtransforms.offset_copy(ax[0].transData, fig=fig,
                                       x=0.05, y=-0.05, units=&#39;inches&#39;)
trans_offset_1 = mtransforms.offset_copy(ax[1].transData, fig=fig,
                                       x=0.05, y=-0.05, units=&#39;inches&#39;)

ax[0].scatter(pointsI[:,1],pointsI[:,0], c=&#39;red&#39;, s=10)
ax[1].scatter(pointsJ[:,1],pointsJ[:,0], c=&#39;red&#39;, s=10)
for i in range(pointsI.shape[0]):
    ax[0].text(pointsI[i,1],pointsI[i,0],f&#39;{i}&#39;, c=&#39;red&#39;, transform=trans_offset_0)
for i in range(pointsJ.shape[0]):
    ax[1].text(pointsJ[i,1],pointsJ[i,0],f&#39;{i}&#39;, c=&#39;red&#39;, transform=trans_offset_1)

ax[0].set_title(&#39;source with pointsI&#39;, fontsize=15)
ax[1].set_title(&#39;target with pointsJ&#39;, fontsize=15)

# invert only rasterized image
ax[0].invert_yaxis()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_30_0.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_30_0.png" />
</div>
</div>
<p>From the landmark points, we can generate a linear transformation <code class="docutils literal notranslate"><span class="pre">L</span></code> and translation <code class="docutils literal notranslate"><span class="pre">T</span></code> which will produce a simple initial affine transformation <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute initial affine transformation from points
L,T = STalign.L_T_from_points(pointsI,pointsJ)
A = STalign.to_A(torch.tensor(L),torch.tensor(T))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">Exception</span>                                 Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[26], line 2</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span style="color: rgb(95,135,135)"># compute initial affine transformation from points</span>
<span class="ansi-green-fg">----&gt; 2</span> L,T <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">STalign</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">L_T_from_points</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">pointsI</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg">pointsJ</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> A <span style="color: rgb(98,98,98)">=</span> STalign<span style="color: rgb(98,98,98)">.</span>to_A(torch<span style="color: rgb(98,98,98)">.</span>tensor(L),torch<span style="color: rgb(98,98,98)">.</span>tensor(T))

File <span class="ansi-green-fg">~/STalign/docs/notebooks/../../STalign/STalign.py:892</span>, in <span class="ansi-cyan-fg">L_T_from_points</span><span class="ansi-blue-fg">(pointsI, pointsJ)</span>
<span class="ansi-green-intense-fg ansi-bold">    890</span> nJ <span style="color: rgb(98,98,98)">=</span> pointsJ<span style="color: rgb(98,98,98)">.</span>shape[<span style="color: rgb(98,98,98)">0</span>]
<span class="ansi-green-intense-fg ansi-bold">    891</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> nI <span style="color: rgb(98,98,98)">!=</span> nJ:
<span class="ansi-green-fg">--&gt; 892</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">Exception</span>(<span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">Number of pointsI (</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>nI<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">) is not equal to number of pointsJ (</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>nJ<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">)</span><span style="color: rgb(175,0,0)">&#39;</span>)
<span class="ansi-green-intense-fg ansi-bold">    893</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> pointsI<span style="color: rgb(98,98,98)">.</span>shape[<span style="color: rgb(98,98,98)">1</span>] <span style="color: rgb(98,98,98)">!=</span> <span style="color: rgb(98,98,98)">2</span>:
<span class="ansi-green-intense-fg ansi-bold">    894</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">raise</span> <span class="ansi-bold" style="color: rgb(215,95,95)">Exception</span>(<span style="color: rgb(175,0,0)">f</span><span style="color: rgb(175,0,0)">&#39;</span><span style="color: rgb(175,0,0)">Number of components of pointsI (</span><span class="ansi-bold" style="color: rgb(175,95,135)">{</span>pointsI<span style="color: rgb(98,98,98)">.</span>shape[<span style="color: rgb(98,98,98)">1</span>]<span class="ansi-bold" style="color: rgb(175,95,135)">}</span><span style="color: rgb(175,0,0)">) should be 2</span><span style="color: rgb(175,0,0)">&#39;</span>)

<span class="ansi-red-fg">Exception</span>: Number of pointsI (10) is not equal to number of pointsJ (15)
</pre></div></div>
</div>
<p>We can show the results of the simple affine transformation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute initial affine transformation from points
AI= STalign.transform_image_source_with_A(A, [YI,XI], I, [YJ,XJ])

# get extent of images
extentI = STalign.extent_from_x((YI,XI))
extentJ = STalign.extent_from_x((YJ,XJ))

fig,ax = plt.subplots(1,2)
#ax[0].imshow(AI[0], extent=extentI)
ax[0].imshow((AI.permute(1,2,0).squeeze()), extent=extentI)
ax[1].imshow((J.transpose(1,2,0).squeeze()), extent=extentJ)

ax[0].set_title(&#39;source with affine transformation&#39;, fontsize=15)
ax[1].set_title(&#39;target&#39;, fontsize=15)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/kalenclifton/STalign/docs/notebooks/../../STalign/STalign.py:1636: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  A = torch.tensor(A)
/Users/kalenclifton/STalign/docs/notebooks/../../STalign/STalign.py:1649: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  XJ = torch.tensor(XJ)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Text(0.5, 1.0, &#39;target&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_34_2.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_34_2.png" />
</div>
</div>
<p>In this case, we can observe that a simple affine alignment is not sufficient to align the single-cell spatial transcriptomics dataset to the H&amp;E staining image. So we will need to perform non-linear local alignments via LDDMM.</p>
<p>There are many parameters that can be tuned for performing this alignment.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig,ax = plt.subplots()
ax.hist(I.ravel())
plt.xlabel(&#39;Intensity&#39;)
plt.ylabel(&#39;Number of Pixels&#39;)
plt.title(&#39;Intensity Histogram of Source Image&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig,ax = plt.subplots()
ax.hist(J.ravel())
plt.xlabel(&#39;Intensity&#39;)
plt.ylabel(&#39;Number of Pixels&#39;)
plt.title(&#39;Intensity Histogram of Target Image&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>WM = torch.ones(J[0].shape)*0.5
WB = torch.ones(J[0].shape)*0.4
WA = torch.ones(J[0].shape)*0.1
muA = torch.sum(WA*J,dim=(-1,-2))/torch.sum(WA)
muB = torch.sum(WB*J,dim=(-1,-2))/torch.sum(WB)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(muA)
print(muB)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>WM = torch.ones(I[0].shape)*0.5
WB = torch.ones(I[0].shape)*0.4
WA = torch.ones(I[0].shape)*0.1
muA = torch.sum(WA*I,dim=(-1,-2))/torch.sum(WA)
muB = torch.sum(WB*I,dim=(-1,-2))/torch.sum(WB)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>print(muA)
print(muB)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%%time

# run LDDMM
# specify device (default device for STalign.LDDMM is cpu)
if torch.cuda.is_available():
    device = &#39;cuda:0&#39;
else:
    device = &#39;cpu&#39;

# keep all other parameters default
params = {&#39;L&#39;:L,&#39;T&#39;:T,
          &#39;niter&#39;:10000,
          &#39;pointsI&#39;:pointsI,
          &#39;pointsJ&#39;:pointsJ,
          &#39;device&#39;:device
          }

out = STalign.LDDMM([YI,XI],I,[YJ,XJ],J,**params)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/kalenclifton/.local/share/virtualenvs/STalign-wXTCUYXW/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/Users/kalenclifton/STalign/docs/notebooks/../../STalign/STalign.py:1294: UserWarning: Data has no positive values, and therefore cannot be log-scaled.
  axE[2].set_yscale(&#39;log&#39;)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
File <span class="ansi-green-fg">&lt;timed exec&gt;:13</span>

File <span class="ansi-green-fg">~/STalign/docs/notebooks/../../STalign/STalign.py:1196</span>, in <span class="ansi-cyan-fg">LDDMM</span><span class="ansi-blue-fg">(xI, I, xJ, J, pointsI, pointsJ, L, T, A, v, xv, a, p, expand, nt, niter, diffeo_start, epL, epT, epV, sigmaM, sigmaB, sigmaA, sigmaR, sigmaP, device, dtype, muB, muA)</span>
<span class="ansi-green-intense-fg ansi-bold">   1194</span> Esave<span style="color: rgb(98,98,98)">.</span>append( tosave )
<span class="ansi-green-intense-fg ansi-bold">   1195</span> <span style="color: rgb(95,135,135)"># gradient update</span>
<span class="ansi-green-fg">-&gt; 1196</span> <span class="ansi-yellow-bg">E</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">backward</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1197</span> <span class="ansi-bold" style="color: rgb(0,135,0)">with</span> torch<span style="color: rgb(98,98,98)">.</span>no_grad():
<span class="ansi-green-intense-fg ansi-bold">   1198</span>     L <span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">=</span> (epL<span style="color: rgb(98,98,98)">/</span>(<span style="color: rgb(98,98,98)">1.0</span> <span style="color: rgb(98,98,98)">+</span> (it<span style="color: rgb(98,98,98)">&gt;</span><span style="color: rgb(98,98,98)">=</span>diffeo_start)<span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">9</span>))<span style="color: rgb(98,98,98)">*</span>L<span style="color: rgb(98,98,98)">.</span>grad

File <span class="ansi-green-fg">~/.local/share/virtualenvs/STalign-wXTCUYXW/lib/python3.10/site-packages/torch/_tensor.py:487</span>, in <span class="ansi-cyan-fg">Tensor.backward</span><span class="ansi-blue-fg">(self, gradient, retain_graph, create_graph, inputs)</span>
<span class="ansi-green-intense-fg ansi-bold">    477</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> has_torch_function_unary(<span style="color: rgb(0,135,0)">self</span>):
<span class="ansi-green-intense-fg ansi-bold">    478</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> handle_torch_function(
<span class="ansi-green-intense-fg ansi-bold">    479</span>         Tensor<span style="color: rgb(98,98,98)">.</span>backward,
<span class="ansi-green-intense-fg ansi-bold">    480</span>         (<span style="color: rgb(0,135,0)">self</span>,),
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    485</span>         inputs<span style="color: rgb(98,98,98)">=</span>inputs,
<span class="ansi-green-intense-fg ansi-bold">    486</span>     )
<span class="ansi-green-fg">--&gt; 487</span> <span class="ansi-yellow-bg">torch</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">autograd</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">backward</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">    488</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">gradient</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">retain_graph</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">create_graph</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">inputs</span>
<span class="ansi-green-intense-fg ansi-bold">    489</span> <span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/.local/share/virtualenvs/STalign-wXTCUYXW/lib/python3.10/site-packages/torch/autograd/__init__.py:200</span>, in <span class="ansi-cyan-fg">backward</span><span class="ansi-blue-fg">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
<span class="ansi-green-intense-fg ansi-bold">    195</span>     retain_graph <span style="color: rgb(98,98,98)">=</span> create_graph
<span class="ansi-green-intense-fg ansi-bold">    197</span> <span style="color: rgb(95,135,135)"># The reason we repeat same the comment below is that</span>
<span class="ansi-green-intense-fg ansi-bold">    198</span> <span style="color: rgb(95,135,135)"># some Python versions print out the first line of a multi-line function</span>
<span class="ansi-green-intense-fg ansi-bold">    199</span> <span style="color: rgb(95,135,135)"># calls in the traceback and some print out the last line</span>
<span class="ansi-green-fg">--&gt; 200</span> <span class="ansi-yellow-bg">Variable</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_execution_engine</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">run_backward</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">  </span><span class="ansi-yellow-bg" style="color: rgb(95,135,135)"># Calls into the C++ engine to run the backward pass</span>
<span class="ansi-green-intense-fg ansi-bold">    201</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">tensors</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">grad_tensors_</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">retain_graph</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">create_graph</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">inputs</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    202</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">allow_unreachable</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">accumulate_grad</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg ansi-bold" style="color: rgb(0,135,0)">True</span><span class="ansi-yellow-bg">)</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_2.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_3.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_4.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_42_4.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># get necessary output variables
A = out[&#39;A&#39;]
v = out[&#39;v&#39;]
xv = out[&#39;xv&#39;]
</pre></div>
</div>
</div>
<p>Plots generated throughout the alignment can be used to give you a sense of whether the parameter choices are appropriate and whether your alignment is converging on a solution.</p>
<p>We can also evaluate the resulting alignment by applying the transformation to visualize how our source and target images were deformed to achieve the alignment.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># apply transform
phii = STalign.build_transform(xv,v,A,XJ=[YJ,XJ],direction=&#39;b&#39;)
phiI = STalign.transform_image_source_to_target(xv,v,A,[YI,XI],I,[YJ,XJ])
phiipointsI = STalign.transform_points_source_to_target(xv,v,A,pointsI)

# plot with grids
fig,ax = plt.subplots()
levels = np.arange(-100000,100000,1000)
ax.contour(XJ,YJ,phii[...,0],colors=&#39;r&#39;,linestyles=&#39;-&#39;,levels=levels)
ax.contour(XJ,YJ,phii[...,1],colors=&#39;g&#39;,linestyles=&#39;-&#39;,levels=levels)
ax.set_aspect(&#39;equal&#39;)
ax.set_title(&#39;source to target&#39;)
ax.imshow(phiI.permute(1,2,0)/torch.max(phiI),extent=extentJ)
ax.scatter(phiipointsI[:,1].detach(),phiipointsI[:,0].detach(),c=&quot;m&quot;)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.collections.PathCollection at 0x3cdd93af0&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_45_1.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_45_1.png" />
</div>
</div>
<p>Finally, we can apply our transform to the original sets of single cell centroid positions to achieve their new aligned positions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># apply transform to original points
tpointsI= STalign.transform_points_source_to_target(xv,v,A, np.stack([yI, xI], 1))

#switch from row column coordinates (y,x) to (x,y)
xI_LDDMM = tpointsI[:,1]
yI_LDDMM = tpointsI[:,0]
</pre></div>
</div>
</div>
<p>And we can visualize the results.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[74]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># plot
#fig,ax = plt.subplots()
#ax.imshow((I).transpose(1,2,0),extent=extentI)
#ax.scatter(phiipointsJ[:,1].detach(),phiipointsJ[:,0].detach(),c=&quot;r&quot;)
#ax.scatter(tpointsI[:,1].detach(),tpointsI[:,0].detach(),s=1,alpha=0.1)

# plot results
fig,ax = plt.subplots()
#ax.scatter(xI,yI,s=1,alpha=0.1, label=&#39;source&#39;)
ax.scatter(xI_LDDMM,yI_LDDMM,s=1,alpha=0.1, label = &#39;source aligned&#39;)
ax.scatter(phiipointsI[:,1].detach(),phiipointsI[:,0].detach(),c=&quot;m&quot;, label=&#39;source landmarks aligned&#39;)
ax.scatter(pointsJ[:,1],pointsJ[:,0], c=&#39;red&#39;, label=&#39;target landmarks&#39;)
ax.imshow((J).transpose(1,2,0),extent=extentJ)

lgnd = plt.legend(loc=&quot;upper right&quot;, scatterpoints=1, fontsize=10)
for handle in lgnd.legend_handles:
    handle.set_sizes([10.0])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_49_0.png" src="../_images/notebooks_merfish-visium-alignment-with-curve-annotator_49_0.png" />
</div>
</div>
<p>And save the new aligned positions by appending to our original data</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[75]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>df3 = pd.DataFrame(

    {

        &quot;aligned_x&quot;: xI_LDDMM,

        &quot;aligned_y&quot;: yI_LDDMM,

    },


)

results = pd.concat([df1, df3], axis=1)
results.head()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[75]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>fov</th>
      <th>volume</th>
      <th>center_x</th>
      <th>center_y</th>
      <th>min_x</th>
      <th>max_x</th>
      <th>min_y</th>
      <th>max_y</th>
      <th>aligned_x</th>
      <th>aligned_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>158338042824236264719696604356349910479</td>
      <td>33</td>
      <td>532.778772</td>
      <td>617.916619</td>
      <td>2666.520010</td>
      <td>614.725219</td>
      <td>621.108019</td>
      <td>2657.545209</td>
      <td>2675.494810</td>
      <td>175.621546</td>
      <td>1306.562409</td>
    </tr>
    <tr>
      <th>1</th>
      <td>260594727341160372355976405428092853003</td>
      <td>33</td>
      <td>1004.430016</td>
      <td>596.808018</td>
      <td>2763.450012</td>
      <td>589.669218</td>
      <td>603.946818</td>
      <td>2757.013212</td>
      <td>2769.886812</td>
      <td>164.680924</td>
      <td>1296.069798</td>
    </tr>
    <tr>
      <th>2</th>
      <td>307643940700812339199503248604719950662</td>
      <td>33</td>
      <td>1267.183208</td>
      <td>578.880018</td>
      <td>2748.978012</td>
      <td>570.877217</td>
      <td>586.882818</td>
      <td>2740.489211</td>
      <td>2757.466812</td>
      <td>162.983247</td>
      <td>1299.773691</td>
    </tr>
    <tr>
      <th>3</th>
      <td>30863303465976316429997331474071348973</td>
      <td>33</td>
      <td>1403.401822</td>
      <td>572.616017</td>
      <td>2766.690012</td>
      <td>564.937217</td>
      <td>580.294818</td>
      <td>2756.581212</td>
      <td>2776.798812</td>
      <td>160.525765</td>
      <td>1298.157619</td>
    </tr>
    <tr>
      <th>4</th>
      <td>313162718584097621688679244357302162401</td>
      <td>33</td>
      <td>507.949497</td>
      <td>608.364018</td>
      <td>2687.418010</td>
      <td>603.061218</td>
      <td>613.666818</td>
      <td>2682.493210</td>
      <td>2692.342810</td>
      <td>172.536918</td>
      <td>1304.732524</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We will finally create a compressed <code class="docutils literal notranslate"><span class="pre">.csv.gz</span></code> file named <code class="docutils literal notranslate"><span class="pre">mouse_brain_map_BrainReceptorShowcase_Slice2_Replicate3_STalign_to_Slice2_Replicate2.csv.gz</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[76]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>results.to_csv(&#39;../merfish_data/mouse_brain_map_BrainReceptorShowcase_Slice2_Replicate3_STalign_to_Visium_tissue_hires_image.csv.gz&#39;,
               compression=&#39;gzip&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, JEFworks Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>